>[!note] SLR + MSE
>The solution to [[4.2a.1 SLR|simple linear regression]] when fitted with [[4.1b Squared Loss|L2 loss]] is
>$$\hat{\theta}_0 = \bar{y} - \hat{\theta}_1\bar{x}$$
>$$\hat{\theta}_1 = r \frac{\sigma_y}{\sigma_x}$$
>where $r$ is the correlation between $x$ and $y$, and $\sigma_x, \sigma_y$ are the standard deviations of $x$ and $y$ respectively.

# Explanation
We normalize a variable $x$ into standard units by subtracting from the mean and dividing by its standard deviation. Mathematically, $\frac{x_i - \bar{x}}{\sigma_x}$. This is also known as the z-score of the normal distribution. 

Let's prove the solution of fitting SLR with MSE, starting with taking the partial derivatives of the MSE with respect to $\theta_0$ and $\theta_1$:
$$\frac{\partial}{\partial \theta_0}MSE=\frac{-2}{n}\sum^{n}_{i=1}[y_i-\theta_0-\theta_1x_i]$$
$$\frac{\partial}{\partial \theta_1}MSE=\frac{-2}{n}\sum^{n}_{i=1}x_i(y_i-\theta_0-\theta_1x_i)$$
Then, we solve the derivatives for $\frac{\partial}{\partial \theta}MSE = 0$:
$$$$