>[!note] Linearity of Variance
>For two independent random variables $X$ and $Y$ in the same probability space, and two constants $c_1$ and $c_2$,
>$$Var(c_1X+c_2Y)=c_1^2Var(X)+c_2^2Var(Y).$$
#### Proof.
As we proved in the [[3.3a Variance|previous note]], $Var(cX)=c^2Var(X)$. Here, we will prove the same for [[2.3 Independent Random Variables|independent random variables]] using linearity of expectation:
$$
\begin{equation}
\begin{aligned}
Var(c_1X+c_2Y) &= \mathbb{E}[(c_1X+c_2Y)^2]-\mathbb{E}[c_1X+c_2Y]^2 \\
&= c_1^2\mathbb{E}[X^2]+2c_1c_2\mathbb{E}[XY]+c_2^2\mathbb{E}[Y^2]-c_1^2\mathbb{E}[X]^2-2c_1c_2\mathbb{E}[X]\mathbb{E}[Y]-c_2^2\mathbb{E}[Y]^2 \\
&= c_1^2(\mathbb{E}[X^2]-\mathbb{E}[X]^2) + 2c_1c_2(\mathbb{E}[XY]-\mathbb{E}[X]\mathbb{E}[Y])+c_2^2(\mathbb{E}[Y^2]-\mathbb{E}[Y]^2) \\
&= c_1^2Var(X)+c_2^2Var(Y)+2c_1c_2(\mathbb{E}[XY]-\mathbb{E}[X]\mathbb{E}[Y]) \\
&= c_1^2Var(X)+c_2^2Var(Y)+2c_1c_2(\mathbb{E}[X]\mathbb{E}[Y]-\mathbb{E}[X]\mathbb{E}[Y]) \\
&= c_1^2Var(X)+c_2^2Var(Y)
\end{aligned}
\end{equation}
$$
Note that the last term cancels out since $X$ and $Y$ are independent, so $\mathbb{E}[XY]=\mathbb{E}[X]\mathbb{E}[Y]$.

>[!example] Coin Tossing (Binomial Variance)
>We now return to the example of coin tosses. Let $X_n=I_1+I_2+...+I_n$ denote the number of heads in $n$ tosses of a biased coin with probability of heads $p$ ($X \enspace \textasciitilde \enspace \text{Bin}(n,p)$). Once again we use the indicator random variable $I_i$, which is either $1$ or $0$ depending on whether or not the $i$th toss returned heads. We also already know that $\mathbb{E}[X_n]=\sum^{n}_{i=1}\mathbb{E}[I_i]=np$. Let's compute the variance of the distribution:
>$$
>\begin{equation}
>\begin{aligned}
>Var(X_n) &= \sum^{n}_{i=1}Var(I_i) \\
>&= \sum^{n}_{i=1}\mathbb{E}[I_i^2]-\mathbb{E}[I_i]^2 \\
>&= \sum^{n}_{i=1}(1^2 \times p + 0^2 \times p)-(1 \times p + 0 \times p)^2 \\
>&= \sum^{n}_{i=1}p-p^2 \\
>&= np(1-p)
\end{aligned}
\end{equation}
>$$

